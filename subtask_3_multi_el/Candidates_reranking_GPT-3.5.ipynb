{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a638d6a-66d3-494d-b1a9-5be7a937dc24",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae3dc53-9cfd-4268-a016-4378fafe39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01234409-81bf-4e0d-a226-d14b7d3fb52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./sample_data/example_candidates_for_reranking.xlsx') # an output file from the SapBERT candidates generation step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fcbfd7-dbf1-4d39-a75e-1421b897beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9840b762-8fd9-4121-9674-cc08450fb4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output file from the candidates generation step contains some artifacts that we must remove\n",
    "df.rename(columns={'Unnamed: 0': 'code'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e355b0d-4d4c-49d4-8b93-6709ebec7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanUp(str):\n",
    "    return str.replace('tensor', '').replace('(', '').replace(')', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318115b5-3981-412c-95b3-9faaed496144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['code'] = df['code'].transform(lambda l: l.strip('tensor()'))\n",
    "df['top_1'] = df['top_1'].transform(cleanUp)\n",
    "df['top_5'] = df['top_5'].transform(cleanUp)\n",
    "df['top_10'] = df['top_10'].transform(cleanUp)\n",
    "df['top_25'] = df['top_25'].transform(cleanUp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ddd9e2-f897-4948-994b-93b580e0f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['code'] == '276412008']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8488245-10e5-4573-86e2-5219e1ef1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_file_name = df.groupby('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bf0a01-9e4e-46bf-baf6-b13a4ac72e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66fac51-12d8-461c-9363-231768d7ff4a",
   "metadata": {},
   "source": [
    "## Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc9db25-8408-4072-9db1-244ee7fd1e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from openai import OpenAI\n",
    "import getpass\n",
    "\n",
    "api_key = getpass.getpass('Enter your OpenAI API key:')\n",
    "\n",
    "model = 'gpt-3.5-turbo-0125'\n",
    "client = OpenAI(api_key=api_key) # best practices right here\n",
    "symptemist_dataset_text_files_path = '../symptemist-complete_240208/symptemist_test/subtask1-ner/txt'\n",
    "output_path = '/output/path' # must have two subdirs - json and dfs for the raw and processed reranking output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39564d2-48db-433d-843e-ffd5aa8ca2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(messages):\n",
    " return client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=messages,\n",
    "      temperature=0.4,\n",
    "      max_tokens=4095,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    ).choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d844319-c57a-4c2b-a206-3350c1b10168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_user_message(message):\n",
    "    return {\n",
    "        'role': 'user',\n",
    "        'content': message\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc77fc69-2fd9-4e4b-a626-22c314361af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_json_from_string(str):\n",
    "    return json.loads(str.strip('`json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35efbc01-d3dd-4476-83ec-591493dceff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_candidates_object_json(entity, candidates_list):\n",
    "    return f\"\"\"{{\n",
    "  \"query term\": \"{entity}\",\n",
    "  \"candidates\": {candidates_list}\n",
    "}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad9dd4c-815c-413e-8fa5-c05c7b8376f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_term_candidates_object_json(\"ENTITY\", '[\"C1\", \"C2\"]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c661c4-db03-490c-b630-5c5fdfa4183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(patient_case_text, term, candidate_list):    \n",
    "    return f\"\"\"You are the AI assistant of a medical doctor. You are given:\n",
    "- a patient case report text\n",
    "- a query term\n",
    "- a list of candidate terms\n",
    "\n",
    "Your task is to normalize the query term to one of the candidate terms that best matches the meaning of the query term, considering the context of the patient case report text. Only choose a term from the given list of candidate terms.\n",
    "\n",
    "Example patient case report:\n",
    "```\n",
    "Remitimos el caso de una paciente de 73 años que consulta por ictericia y síndrome constitucional de menos de 2 meses de evolución. En el Servicio de Urgencias se evidenció una gran hepatomegalia dolorosa y en las pruebas analíticas destacaba leucocitosis con neutrofilia y alteración mixta del perfil hepático de predominio colestásico (fosfatasa alcalina y GGT más de 10 veces el valor normal y ALT y AST menos de 3 veces el valor normal), sin insuficiencia hepática.\n",
    "\n",
    "A las 24 horas del ingreso comenzó con un cuadro confusional que evolucionó rápidamente al coma y fiebre mayor de 39 ºC. Se realizaron ecografía y TAC abdominales, objetivando múltiples lesiones hepáticas ocupantes de espacio, hipodensas, sólidas y que se distribuían en ambos lóbulos ocupando prácticamente todo el órgano, sugerentes de MTS. No se encontró ningún foco infeccioso, varios hemocultivos fueron estériles y, mediante TAC, se había descartado la presencia de lesiones cerebrales.\n",
    "\n",
    "Analíticamente se deterioró el perfil hepático presentando una importante elevación de transaminasas en el rango de hepatitis aguda (ALT y AST mayores de 20 veces el valor normal con importante aumento de la LDH) y datos de insuficiencia hepática con deterioro progresivo de la función renal.\n",
    "A pesar de tratamiento intensivo con medidas antiencefalopatía, drogas vasoactivas, antibióticos de amplio espectro a dosis elevadas (para cubrir como posible foco el SNC) y transfusión de plasma fresco congelado, la paciente falleció a los 5 días del ingreso como consecuencia de un fallo multiorgánico, sin llegar a establecerse la naturaleza de las lesiones hepáticas ni su origen debido a la rápida evolución. Por este motivo se realizó la autopsia clínica.\n",
    "En la necropsia se confirmó la existencia de MTS hepáticas extensas. El tumor primario fue un adenocarcinoma cecal de 3 x 2 cm de diámetro, estadio D de Dukes y IV de Astler-Coller. Presentaba infiltración de serosa y grasa perivascular e infiltración linfática y venular. MTS en ganglios locorregionales infradiafragmáticos y en parénquima pulmonar. Además se observaron lesiones de hepatitis isquémica asociada y colangiolitis y extensa autolisis pancreática y peripancreática.\n",
    "```\n",
    "\n",
    "Examples query and candidate terms:\n",
    "```\n",
    "{{\n",
    "    \"query term\": \"neutrophilia\",\n",
    "    \"candidates\": [\"pseudoneutrofilia\", \"neutrofilia\", \"leucocitosis neutrofílica\", \"neutrofilia (hallazgo)\"]\n",
    "}}\n",
    "```\n",
    "\n",
    "Example result:\n",
    "```\n",
    "{{\n",
    "    \"answer\": \"neutrofilia\"\n",
    "}}\n",
    "```\n",
    "\n",
    "Now please normalize the following:\n",
    "\n",
    "Patient case report: \n",
    "```\n",
    "{patient_case_text}\n",
    "```\n",
    "\n",
    "Query term and candidate terms:\n",
    "```\n",
    "{get_term_candidates_object_json(term, candidate_list)}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c456a5-a5d6-4a51-af90-52dbe109b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_prompt(\"CASE TEXT\", \"a\", [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7048ad-632f-4496-ac2e-14861791bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_candidates(file_name, terms, candidate_term_lists, candidate_code_lists):\n",
    "    with open(f'{symptemist_dataset_text_files_path}/{file_name}.txt', 'r', encoding='utf8') as patient_case_file:\n",
    "        patient_case_text = patient_case_file.read()\n",
    "\n",
    "        original_terms = []\n",
    "        best_candidate_terms = []\n",
    "        best_candidate_codes = []\n",
    "        \n",
    "        for term_index, (term, candidate_terms, candidate_codes) in enumerate(zip(terms, candidate_term_lists, candidate_code_lists)):\n",
    "            prompt = get_prompt(patient_case_text, term, candidate_terms)\n",
    "            messages = [format_user_message(prompt)]\n",
    "            result = infer(messages)\n",
    "        \n",
    "            with open(f'{output_path}/json/{file_name}-{term_index}.json', 'w', encoding='utf8') as out_file:\n",
    "                out_file.write(result)\n",
    "\n",
    "            result_json = extract_json_from_string(result)\n",
    "            best_candidate_term = result_json['answer']\n",
    "\n",
    "            original_terms.append(term)\n",
    "            if best_candidate_term not in candidate_terms:\n",
    "                print(f'Bad result. No matching term in candidates list. Skipping {term} in file {file_name}.')\n",
    "                best_candidate_terms.append(None)\n",
    "                best_candidate_codes.append(0)\n",
    "                continue\n",
    "            \n",
    "            best_candidate_terms.append(best_candidate_term)\n",
    "            best_candidate_codes.append(candidate_codes[candidate_terms.index(best_candidate_term)])\n",
    "\n",
    "        return original_terms, best_candidate_terms, best_candidate_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8203fe-591b-4f03-bbd6-2a7b71e88c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "\n",
    "done = [file_name.strip('.tsv') for file_name in os.listdir(f'{output_path}/dfs')]\n",
    "\n",
    "for group_file_name, group_data in grouped_by_file_name:\n",
    "    if group_file_name in done: \n",
    "        print(f'Skipping {group_file_name}')\n",
    "        continue\n",
    "\n",
    "    print(f'Processing {group_file_name}')\n",
    "    \n",
    "    top_texts_list = []\n",
    "    top_codes_list = []\n",
    "    entities = []\n",
    "\n",
    "    for _, row in group_data.iterrows():\n",
    "        texts_column_name, codes_column_name = 'top_5_texts', 'top_5'\n",
    "        entities.append(row['term'])\n",
    "        top_texts_list.append(ast.literal_eval(row[texts_column_name]))\n",
    "        top_codes_list.append(ast.literal_eval(row[codes_column_name]))\n",
    "\n",
    "    original_entities, best_texts, best_codes = determine_best_candidates(group_file_name, entities, top_texts_list, top_codes_list)\n",
    "    \n",
    "    result_df = group_data.copy(deep=True)\n",
    "    result_df['original_entity'] = original_entities\n",
    "    result_df['new_best_text'] = best_texts\n",
    "    result_df['new_best_code'] = best_codes\n",
    "    result_df.to_csv(f'{output_path}/dfs/{group_file_name}.tsv', sep='\\t', encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125dc327-a259-4eb9-a5c6-3bfe8b375f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "result_dfs = []\n",
    "\n",
    "for df_file_name in os.listdir(f'{output_path}/dfs'):\n",
    "    result_dfs.append(pd.read_csv(f'{output_path}/dfs/{df_file_name}', sep='\\t', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d309d8-cdb1-41f2-87de-d5e159f1387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat(result_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a537a-4dbc-4ea6-9991-ef281baad5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('reranking_results.tsv', sep='\\t', encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8d4cd-2497-4d0c-b801-b41cfe468405",
   "metadata": {},
   "outputs": [],
   "source": [
    "final['code'] = final['code'].astype(str)\n",
    "final['new_best_code'] = final['new_best_code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b830feb5-c037-44f7-aa8a-691b42698837",
   "metadata": {},
   "outputs": [],
   "source": [
    "final[['code', 'new_best_code']].to_excel(f'{output_path}/reranking_result_codes.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cc7035-1011-42c4-bec8-d1abf19ae747",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_excel(f'{output_path}/reranking_results.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
